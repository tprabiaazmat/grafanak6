# k6 Time Series

We want to introduce the time series concept to k6 for getting the benefit of efficiently identifying the combination between a metric and the relative tags.

A summary of the benefits it brings across the platform:

* It allows executing faster lookups and comparisons by a single value, the ID (hash) of the series.
* It reduces the storage by allocating just one time a possible combination (the time series) and referencing it in all other places. 
* It allows aggregating data by time series.
* It enables easier detection of high cardinality issues just by counting the entire unique data set of generated time series.
* It enables time series based outputs to simplify the integration's logic (e.g. Prometheus).

## Data model

#### Metrics and Series

* Metric (name, type)
* Time Series (metric, tags)
* Sample (timestamp, value, time series ref)
* Tag - (aka [k6/1831](https://github.com/grafana/k6/issues/1831))

```go
// This is the current k6 Metric polished from the Thresholds dependencies.
type Metric struct {
	name     string
	type     MetricType
	contains ValueType
}

type Tag struct {
    Key, Value string
}

type TimeSeries struct {
	// hash is a 64bit hash generated
	// hashing the metric name and the tags set.
	// The tag set must be sorted to guarantee the hashing consistency.
	// The value must be consistent across distributed instances.
	hash uint64 

	// sequence is the unique and sequential number in the current instance.
	// It is used for storing multiple time series in a slice
	// for getting fast access by slice's indexing.
	sequence uint32
	
	// metricName is the name of the related metric.
	metricName string

	// tags is the sorted list of tags.
	tags   []Tag

	// tagIndex provides a resolver by single Tag.
	// It links for each Tag's key its related index in the tags slice.
	tagIndex map[string]int
}

type Sample struct {
        TimeSeries *TimeSeries
        Timestamp uint64
        Value float64
}
```

#### Hash

The time series Hash are `uint64` values generated by hashing the metric name and the tags' sorted key-value pairs.

#### Sink

The sinks are implemented by metric types and they keep values up to date by time series and/or aggregated views:

* Counter: a monotonic increasing value
* Gauge: the latest value
* Rate: the percentage of non-zero values across the total of the events 
* SparseHistogram: counters per dynamic ranges (buckets) - https://grafana.com/blog/2021/11/03/how-sparse-histograms-can-improve-efficiency-precision-and-mergeability-in-prometheus-tsdb

## Storage

#### Time Series database (aka tsdb)

We need to store all the time series generated from `k6` run during the execution so the other components (mostly the outputs) could query the storage for getting the value of the time series. It's expected to be in-memory and it should be concurrent-safe.

It can extend the current `metrics.Registry` struct adding the following function:

```go
type Registry struct {
    ...
    GetOrCreateSeries(metric *Metric, tags []Tag) *TimeSeries
}
```

## Samples generation

The current sampling process is controlled by the `metrics.PushIfNotDone` method. All the actual callers should resolve the time series from the storage before push a new Sample, or in the event no one is found the storage will create and insert a new one.
It requires the dependency from the time series database for all the callers (e.g. executors, JavaScript modules). Most of them already have the metrics.Registry dependency.

## metrics.Ingester

Ingester is responsible for resolving the entire set of Sinks impacted from the ingested time series then it adds the Sample's value to the resolved Sinks.

##### Example

In a `t0` where the status of the seen time series is:

```text
http_req_duration{status:200,method:GET}
http_req_duration{method:GET}
http_req_duration{status:200}
http_req_another_one{status:200}
```

The Ingester in the case of a collected Sample `http_req_duration{status:200,method:GET}` then it resolves the dependencies with the other seen time series in a unique set where it contains the following time series  `http_req_duration{status:200}` and `http_req_duration{method:GET}`. It can now resolve the relative Metric's Sinks and it invokes them passing the Sample's value.

## Known issues

* Name and URL tags: `k6` is tagging HTTP requests with the URL. It will create a high cardinality issue for the time series data model. This should be fixed by adding the possibility to not store all the tags as indexable, having the availability to set them as `metadata` and exclude them from the time series generation. An alternative workaround could be to exclude them from the default set of enabled tags.
* We need to keep all the data for the Trend type for computing the percentiles. We plan to migrate to some form of approximation (Sparse Histogram, OpenHistogram, T-Digest, etc..)

## Acceptance criteria

- [ ] Can the new model enable the Prometheus output integration?
- [ ] Can the new model enable cloud aggregation?
- [ ] Can the new model work with Thresholds?
- [ ] Is the memory footprint generated from the new model reduced? If not, is it acceptable?
- [ ] Is the CPUs usage generated from the new model reduced? If not, is it acceptable?
